{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cef6155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e25254",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels)  = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd428ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe56896ea20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[1262,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69a78b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 32, 32, 3), (10000, 1), (2000, 32, 32, 3), (2000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_rate = 0.2\n",
    "train_idx = np.random.permutation(np.arange(train_images.shape[0]))\n",
    "train_idx = train_idx[:round(train_idx.shape[0]*select_rate)]\n",
    "train_images,train_labels = train_images[train_idx,],train_labels[train_idx,]\n",
    "test_idx = np.random.permutation(np.arange(test_images.shape[0]))\n",
    "test_idx = test_idx[:round(test_idx.shape[0]*select_rate)]\n",
    "test_images,test_labels = test_images[test_idx,],test_labels[test_idx,]\n",
    "train_images,test_images = train_images/255.0,test_images/255.0\n",
    "(train_images.shape,train_labels.shape,test_images.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e159baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.RandomFlip(\"horizontal\",input_shape=(32,32,3)))\n",
    "model.add(layers.RandomRotation(0.1))\n",
    "model.add(layers.RandomZoom(0.1))\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cdd0817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "313/313 [==============================] - 16s 44ms/step - loss: 1.9993 - accuracy: 0.2545 - val_loss: 1.6905 - val_accuracy: 0.3670\n",
      "Epoch 2/200\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.7128 - accuracy: 0.3748 - val_loss: 1.7355 - val_accuracy: 0.3905\n",
      "Epoch 3/200\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 1.5978 - accuracy: 0.4187 - val_loss: 1.6304 - val_accuracy: 0.4210\n",
      "Epoch 4/200\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 1.5310 - accuracy: 0.4436 - val_loss: 1.5425 - val_accuracy: 0.4400\n",
      "Epoch 5/200\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 1.4907 - accuracy: 0.4579 - val_loss: 1.4258 - val_accuracy: 0.4830\n",
      "Epoch 6/200\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 1.4162 - accuracy: 0.4909 - val_loss: 1.5581 - val_accuracy: 0.4570\n",
      "Epoch 7/200\n",
      "313/313 [==============================] - 11s 37ms/step - loss: 1.3931 - accuracy: 0.4945 - val_loss: 1.3772 - val_accuracy: 0.4925\n",
      "Epoch 8/200\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 1.3599 - accuracy: 0.5020 - val_loss: 1.3798 - val_accuracy: 0.5090\n",
      "Epoch 9/200\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 1.3334 - accuracy: 0.5193 - val_loss: 1.3114 - val_accuracy: 0.5340\n",
      "Epoch 10/200\n",
      "313/313 [==============================] - 11s 37ms/step - loss: 1.3180 - accuracy: 0.5247 - val_loss: 1.2971 - val_accuracy: 0.5295\n",
      "Epoch 11/200\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 1.2759 - accuracy: 0.5372 - val_loss: 1.2316 - val_accuracy: 0.5475\n",
      "Epoch 12/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 1.2625 - accuracy: 0.5421 - val_loss: 1.3289 - val_accuracy: 0.5155\n",
      "Epoch 13/200\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 1.2268 - accuracy: 0.5625 - val_loss: 1.3228 - val_accuracy: 0.5165\n",
      "Epoch 14/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 1.2232 - accuracy: 0.5607 - val_loss: 1.1891 - val_accuracy: 0.5585\n",
      "Epoch 15/200\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 1.2006 - accuracy: 0.5675 - val_loss: 1.2894 - val_accuracy: 0.5465\n",
      "Epoch 16/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 1.1925 - accuracy: 0.5691 - val_loss: 1.1908 - val_accuracy: 0.5695\n",
      "Epoch 17/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 1.1791 - accuracy: 0.5818 - val_loss: 1.1799 - val_accuracy: 0.5745\n",
      "Epoch 18/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 1.1603 - accuracy: 0.5828 - val_loss: 1.1862 - val_accuracy: 0.5770\n",
      "Epoch 19/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 1.1650 - accuracy: 0.5853 - val_loss: 1.1537 - val_accuracy: 0.5905\n",
      "Epoch 20/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 1.1342 - accuracy: 0.5914 - val_loss: 1.1908 - val_accuracy: 0.5805\n",
      "Epoch 21/200\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 1.1116 - accuracy: 0.6030 - val_loss: 1.2320 - val_accuracy: 0.5640\n",
      "Epoch 22/200\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 1.1039 - accuracy: 0.5999 - val_loss: 1.1381 - val_accuracy: 0.5845\n",
      "Epoch 23/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 1.1016 - accuracy: 0.6017 - val_loss: 1.2221 - val_accuracy: 0.5640\n",
      "Epoch 24/200\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 1.0998 - accuracy: 0.6089 - val_loss: 1.2339 - val_accuracy: 0.5760\n",
      "Epoch 25/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 1.0919 - accuracy: 0.6108 - val_loss: 1.2039 - val_accuracy: 0.5760\n",
      "Epoch 26/200\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 1.0866 - accuracy: 0.6073 - val_loss: 1.2857 - val_accuracy: 0.5625\n",
      "Epoch 27/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 1.0662 - accuracy: 0.6171 - val_loss: 1.1440 - val_accuracy: 0.5915\n",
      "Epoch 28/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 1.0477 - accuracy: 0.6243 - val_loss: 1.1133 - val_accuracy: 0.6110\n",
      "Epoch 29/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 1.0446 - accuracy: 0.6254 - val_loss: 1.1462 - val_accuracy: 0.5955\n",
      "Epoch 30/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 1.0355 - accuracy: 0.6332 - val_loss: 1.1147 - val_accuracy: 0.6125\n",
      "Epoch 31/200\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 1.0196 - accuracy: 0.6312 - val_loss: 1.0922 - val_accuracy: 0.5995\n",
      "Epoch 32/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 1.0181 - accuracy: 0.6383 - val_loss: 1.1709 - val_accuracy: 0.5925\n",
      "Epoch 33/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.9988 - accuracy: 0.6444 - val_loss: 1.1493 - val_accuracy: 0.5920\n",
      "Epoch 34/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 1.0028 - accuracy: 0.6433 - val_loss: 1.1297 - val_accuracy: 0.6090\n",
      "Epoch 35/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.9856 - accuracy: 0.6495 - val_loss: 1.1255 - val_accuracy: 0.5990\n",
      "Epoch 36/200\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 0.9840 - accuracy: 0.6485 - val_loss: 1.0818 - val_accuracy: 0.6265\n",
      "Epoch 37/200\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 0.9886 - accuracy: 0.6448 - val_loss: 1.1410 - val_accuracy: 0.5970\n",
      "Epoch 38/200\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.9700 - accuracy: 0.6542 - val_loss: 1.1064 - val_accuracy: 0.6110\n",
      "Epoch 39/200\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 0.9616 - accuracy: 0.6509 - val_loss: 1.2000 - val_accuracy: 0.5840\n",
      "Epoch 40/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 0.9545 - accuracy: 0.6563 - val_loss: 1.1657 - val_accuracy: 0.5975\n",
      "Epoch 41/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 0.9396 - accuracy: 0.6672 - val_loss: 1.1246 - val_accuracy: 0.6125\n",
      "Epoch 42/200\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.9447 - accuracy: 0.6615 - val_loss: 1.2783 - val_accuracy: 0.5755\n",
      "Epoch 43/200\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.9358 - accuracy: 0.6729 - val_loss: 1.2056 - val_accuracy: 0.5955\n",
      "Epoch 44/200\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.9340 - accuracy: 0.6661 - val_loss: 1.1132 - val_accuracy: 0.6180\n",
      "Epoch 45/200\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.9451 - accuracy: 0.6594 - val_loss: 1.1054 - val_accuracy: 0.6120\n",
      "Epoch 46/200\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.9272 - accuracy: 0.6636 - val_loss: 1.1706 - val_accuracy: 0.6030\n",
      "Epoch 47/200\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.9095 - accuracy: 0.6737 - val_loss: 1.1350 - val_accuracy: 0.6155\n",
      "Epoch 48/200\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.9218 - accuracy: 0.6732 - val_loss: 1.1194 - val_accuracy: 0.6015\n",
      "Epoch 49/200\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.9066 - accuracy: 0.6749 - val_loss: 1.0692 - val_accuracy: 0.6265\n",
      "Epoch 50/200\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.9158 - accuracy: 0.6717 - val_loss: 1.1231 - val_accuracy: 0.6150\n",
      "Epoch 51/200\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.9085 - accuracy: 0.6751 - val_loss: 1.0788 - val_accuracy: 0.6175\n",
      "Epoch 52/200\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.8882 - accuracy: 0.6823 - val_loss: 1.2915 - val_accuracy: 0.5825\n",
      "Epoch 53/200\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8904 - accuracy: 0.6817 - val_loss: 1.1213 - val_accuracy: 0.6150\n",
      "Epoch 54/200\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.8786 - accuracy: 0.6856 - val_loss: 1.2210 - val_accuracy: 0.6005\n",
      "Epoch 55/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 0.8940 - accuracy: 0.6823 - val_loss: 1.1497 - val_accuracy: 0.6140\n",
      "Epoch 56/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.8760 - accuracy: 0.6895 - val_loss: 1.1569 - val_accuracy: 0.6175\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 18s 56ms/step - loss: 0.8562 - accuracy: 0.6959 - val_loss: 1.1260 - val_accuracy: 0.6220\n",
      "Epoch 58/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.8634 - accuracy: 0.6899 - val_loss: 1.1381 - val_accuracy: 0.6270\n",
      "Epoch 59/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.8718 - accuracy: 0.6908 - val_loss: 1.0917 - val_accuracy: 0.6150\n",
      "Epoch 60/200\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 0.8577 - accuracy: 0.6919 - val_loss: 1.1371 - val_accuracy: 0.6210\n",
      "Epoch 61/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.8553 - accuracy: 0.6970 - val_loss: 1.1785 - val_accuracy: 0.6185\n",
      "Epoch 62/200\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 0.8485 - accuracy: 0.6963 - val_loss: 1.2181 - val_accuracy: 0.5985\n",
      "Epoch 63/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.8494 - accuracy: 0.6982 - val_loss: 1.1444 - val_accuracy: 0.6135\n",
      "Epoch 64/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.8506 - accuracy: 0.7010 - val_loss: 1.0861 - val_accuracy: 0.6285\n",
      "Epoch 65/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.8483 - accuracy: 0.6910 - val_loss: 1.3452 - val_accuracy: 0.5835\n",
      "Epoch 66/200\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.8449 - accuracy: 0.6991 - val_loss: 1.0935 - val_accuracy: 0.6255\n",
      "Epoch 67/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.8405 - accuracy: 0.6974 - val_loss: 1.0965 - val_accuracy: 0.6370\n",
      "Epoch 68/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.8420 - accuracy: 0.6961 - val_loss: 1.0985 - val_accuracy: 0.6385\n",
      "Epoch 69/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.8253 - accuracy: 0.7020 - val_loss: 1.1322 - val_accuracy: 0.6200\n",
      "Epoch 70/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.8393 - accuracy: 0.6975 - val_loss: 1.1123 - val_accuracy: 0.6275\n",
      "Epoch 71/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.8143 - accuracy: 0.7093 - val_loss: 1.1154 - val_accuracy: 0.6360\n",
      "Epoch 72/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 0.8126 - accuracy: 0.7090 - val_loss: 1.1312 - val_accuracy: 0.6260\n",
      "Epoch 73/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.8031 - accuracy: 0.7125 - val_loss: 1.1683 - val_accuracy: 0.6245\n",
      "Epoch 74/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.7991 - accuracy: 0.7123 - val_loss: 1.1537 - val_accuracy: 0.6200\n",
      "Epoch 75/200\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 0.8201 - accuracy: 0.7040 - val_loss: 1.1949 - val_accuracy: 0.6100\n",
      "Epoch 76/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.8041 - accuracy: 0.7101 - val_loss: 1.1733 - val_accuracy: 0.6250\n",
      "Epoch 77/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.7964 - accuracy: 0.7148 - val_loss: 1.1371 - val_accuracy: 0.6265\n",
      "Epoch 78/200\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 0.8014 - accuracy: 0.7121 - val_loss: 1.1525 - val_accuracy: 0.6355\n",
      "Epoch 79/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.8020 - accuracy: 0.7078 - val_loss: 1.1478 - val_accuracy: 0.6315\n",
      "Epoch 80/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7962 - accuracy: 0.7176 - val_loss: 1.1437 - val_accuracy: 0.6305\n",
      "Epoch 81/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.7883 - accuracy: 0.7145 - val_loss: 1.1299 - val_accuracy: 0.6365\n",
      "Epoch 82/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7858 - accuracy: 0.7165 - val_loss: 1.1929 - val_accuracy: 0.6100\n",
      "Epoch 83/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.7918 - accuracy: 0.7154 - val_loss: 1.1459 - val_accuracy: 0.6410\n",
      "Epoch 84/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7745 - accuracy: 0.7198 - val_loss: 1.1947 - val_accuracy: 0.6135\n",
      "Epoch 85/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 0.7739 - accuracy: 0.7233 - val_loss: 1.1876 - val_accuracy: 0.6220\n",
      "Epoch 86/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7817 - accuracy: 0.7167 - val_loss: 1.2073 - val_accuracy: 0.6180\n",
      "Epoch 87/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.7847 - accuracy: 0.7224 - val_loss: 1.1454 - val_accuracy: 0.6280\n",
      "Epoch 88/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.7502 - accuracy: 0.7329 - val_loss: 1.2277 - val_accuracy: 0.6180\n",
      "Epoch 89/200\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 0.7614 - accuracy: 0.7287 - val_loss: 1.1400 - val_accuracy: 0.6315\n",
      "Epoch 90/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7634 - accuracy: 0.7249 - val_loss: 1.2033 - val_accuracy: 0.6385\n",
      "Epoch 91/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.7624 - accuracy: 0.7259 - val_loss: 1.1315 - val_accuracy: 0.6315\n",
      "Epoch 92/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 0.7693 - accuracy: 0.7239 - val_loss: 1.1847 - val_accuracy: 0.6270\n",
      "Epoch 93/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 0.7585 - accuracy: 0.7237 - val_loss: 1.2154 - val_accuracy: 0.6210\n",
      "Epoch 94/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7730 - accuracy: 0.7227 - val_loss: 1.1756 - val_accuracy: 0.6260\n",
      "Epoch 95/200\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 0.7602 - accuracy: 0.7272 - val_loss: 1.3496 - val_accuracy: 0.5945\n",
      "Epoch 96/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.7477 - accuracy: 0.7319 - val_loss: 1.1473 - val_accuracy: 0.6400\n",
      "Epoch 97/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.7410 - accuracy: 0.7355 - val_loss: 1.1490 - val_accuracy: 0.6345\n",
      "Epoch 98/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 0.7561 - accuracy: 0.7327 - val_loss: 1.2080 - val_accuracy: 0.6195\n",
      "Epoch 99/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7605 - accuracy: 0.7270 - val_loss: 1.2203 - val_accuracy: 0.6215\n",
      "Epoch 100/200\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.7620 - accuracy: 0.7218 - val_loss: 1.1952 - val_accuracy: 0.6265\n",
      "Epoch 101/200\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 0.7489 - accuracy: 0.7322 - val_loss: 1.1659 - val_accuracy: 0.6310\n",
      "Epoch 102/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7477 - accuracy: 0.7308 - val_loss: 1.2044 - val_accuracy: 0.6240\n",
      "Epoch 103/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7435 - accuracy: 0.7322 - val_loss: 1.1891 - val_accuracy: 0.6315\n",
      "Epoch 104/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 0.7306 - accuracy: 0.7397 - val_loss: 1.2506 - val_accuracy: 0.6205\n",
      "Epoch 105/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.7441 - accuracy: 0.7320 - val_loss: 1.1680 - val_accuracy: 0.6320\n",
      "Epoch 106/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.7485 - accuracy: 0.7295 - val_loss: 1.1235 - val_accuracy: 0.6445\n",
      "Epoch 107/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 0.7227 - accuracy: 0.7431 - val_loss: 1.1764 - val_accuracy: 0.6315\n",
      "Epoch 108/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 0.7253 - accuracy: 0.7380 - val_loss: 1.1990 - val_accuracy: 0.6275\n",
      "Epoch 109/200\n",
      "313/313 [==============================] - 17s 56ms/step - loss: 0.7335 - accuracy: 0.7416 - val_loss: 1.2223 - val_accuracy: 0.6295\n",
      "Epoch 110/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.7202 - accuracy: 0.7421 - val_loss: 1.1677 - val_accuracy: 0.6315\n",
      "Epoch 111/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.7251 - accuracy: 0.7410 - val_loss: 1.2875 - val_accuracy: 0.6140\n",
      "Epoch 112/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7247 - accuracy: 0.7434 - val_loss: 1.1668 - val_accuracy: 0.6360\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 17s 55ms/step - loss: 0.7146 - accuracy: 0.7458 - val_loss: 1.1965 - val_accuracy: 0.6295\n",
      "Epoch 114/200\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.7271 - accuracy: 0.7406 - val_loss: 1.2749 - val_accuracy: 0.6035\n",
      "Epoch 115/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.7165 - accuracy: 0.7452 - val_loss: 1.2058 - val_accuracy: 0.6205\n",
      "Epoch 116/200\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.7010 - accuracy: 0.7500 - val_loss: 1.2138 - val_accuracy: 0.6245\n",
      "Epoch 117/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.7099 - accuracy: 0.7473 - val_loss: 1.1932 - val_accuracy: 0.6345\n",
      "Epoch 118/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.7206 - accuracy: 0.7421 - val_loss: 1.2564 - val_accuracy: 0.6115\n",
      "Epoch 119/200\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.7284 - accuracy: 0.7423 - val_loss: 1.2377 - val_accuracy: 0.6215\n",
      "Epoch 120/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.7086 - accuracy: 0.7457 - val_loss: 1.1704 - val_accuracy: 0.6295\n",
      "Epoch 121/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.7007 - accuracy: 0.7489 - val_loss: 1.2450 - val_accuracy: 0.6305\n",
      "Epoch 122/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.6988 - accuracy: 0.7527 - val_loss: 1.1916 - val_accuracy: 0.6320\n",
      "Epoch 123/200\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 0.6966 - accuracy: 0.7493 - val_loss: 1.2230 - val_accuracy: 0.6275\n",
      "Epoch 124/200\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.6949 - accuracy: 0.7532 - val_loss: 1.2313 - val_accuracy: 0.6225\n",
      "Epoch 125/200\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.7100 - accuracy: 0.7473 - val_loss: 1.2360 - val_accuracy: 0.6295\n",
      "Epoch 126/200\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.6910 - accuracy: 0.7537 - val_loss: 1.2433 - val_accuracy: 0.6270\n",
      "Epoch 127/200\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.6731 - accuracy: 0.7606 - val_loss: 1.2183 - val_accuracy: 0.6395\n",
      "Epoch 128/200\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.6959 - accuracy: 0.7534 - val_loss: 1.2588 - val_accuracy: 0.6335\n",
      "Epoch 129/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.7004 - accuracy: 0.7531 - val_loss: 1.2574 - val_accuracy: 0.6230\n",
      "Epoch 130/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.6785 - accuracy: 0.7532 - val_loss: 1.2562 - val_accuracy: 0.6270\n",
      "Epoch 131/200\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.6876 - accuracy: 0.7542 - val_loss: 1.2530 - val_accuracy: 0.6260\n",
      "Epoch 132/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.6896 - accuracy: 0.7540 - val_loss: 1.2009 - val_accuracy: 0.6415\n",
      "Epoch 133/200\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.6892 - accuracy: 0.7543 - val_loss: 1.2357 - val_accuracy: 0.6395\n",
      "Epoch 134/200\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 0.6794 - accuracy: 0.7570 - val_loss: 1.2426 - val_accuracy: 0.6295\n",
      "Epoch 135/200\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.6751 - accuracy: 0.7583 - val_loss: 1.2540 - val_accuracy: 0.6255\n",
      "Epoch 136/200\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.6732 - accuracy: 0.7629 - val_loss: 1.1823 - val_accuracy: 0.6365\n",
      "Epoch 137/200\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.6885 - accuracy: 0.7560 - val_loss: 1.2034 - val_accuracy: 0.6305\n",
      "Epoch 138/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.6897 - accuracy: 0.7575 - val_loss: 1.2516 - val_accuracy: 0.6260\n",
      "Epoch 139/200\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.6876 - accuracy: 0.7520 - val_loss: 1.2484 - val_accuracy: 0.6330\n",
      "Epoch 140/200\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.6829 - accuracy: 0.7573 - val_loss: 1.1941 - val_accuracy: 0.6410\n",
      "Epoch 141/200\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.6806 - accuracy: 0.7631 - val_loss: 1.2931 - val_accuracy: 0.6145\n",
      "Epoch 142/200\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.6871 - accuracy: 0.7516 - val_loss: 1.1932 - val_accuracy: 0.6375\n",
      "Epoch 143/200\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6848 - accuracy: 0.7591 - val_loss: 1.2151 - val_accuracy: 0.6260\n",
      "Epoch 144/200\n",
      "313/313 [==============================] - 27s 86ms/step - loss: 0.6658 - accuracy: 0.7644 - val_loss: 1.2480 - val_accuracy: 0.6335\n",
      "Epoch 145/200\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.6700 - accuracy: 0.7574 - val_loss: 1.2894 - val_accuracy: 0.6265\n",
      "Epoch 146/200\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 0.6727 - accuracy: 0.7594 - val_loss: 1.2273 - val_accuracy: 0.6340\n",
      "Epoch 147/200\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6653 - accuracy: 0.7642 - val_loss: 1.1966 - val_accuracy: 0.6325\n",
      "Epoch 148/200\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6840 - accuracy: 0.7547 - val_loss: 1.3126 - val_accuracy: 0.6065\n",
      "Epoch 149/200\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.6663 - accuracy: 0.7605 - val_loss: 1.2294 - val_accuracy: 0.6265\n",
      "Epoch 150/200\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.6720 - accuracy: 0.7582 - val_loss: 1.3215 - val_accuracy: 0.6160\n",
      "Epoch 151/200\n",
      "313/313 [==============================] - 17s 53ms/step - loss: 0.6689 - accuracy: 0.7579 - val_loss: 1.2694 - val_accuracy: 0.6205\n",
      "Epoch 152/200\n",
      "145/313 [============>.................] - ETA: 9s - loss: 0.6614 - accuracy: 0.7659"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-07ac997708ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m              \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m              )\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(True),\n",
    "             metrics=['accuracy']\n",
    "             )\n",
    "history = model.fit(train_images,train_labels,batch_size=32,epochs=20,validation_data=(test_images,test_labels))\n",
    "test_loss,test_acc=model.evaluate(test_images,test_labels,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f52b61a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0a51d9a44f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lower right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'],label='acc')\n",
    "plt.plot(history.history['val_accuracy'],label='val_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('history accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cea1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
